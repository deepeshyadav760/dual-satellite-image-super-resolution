{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a682fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#           DUAL-IMAGE SUPER-RESOLUTION MODEL TRAINING NOTEBOOK\n",
    "# ==============================================================================\n",
    "\n",
    "# Objective: Train a state-of-the-art super-resolution model and save it to\n",
    "#            Google Drive.\n",
    "\n",
    "# Instructions:\n",
    "# 1. Place your 'hr_image-*.tfrecord' file(s) in a folder in your Google Drive.\n",
    "# 2. Update the 'TFRECORD_FOLDER_PATH' variable in Step 2 to point to that folder.\n",
    "# 3. Go to 'Runtime' -> 'Change runtime type' and select 'T4 GPU'.\n",
    "# 4. Run each cell sequentially.\n",
    "# ==============================================================================\n",
    "\n",
    "# @title Step 1: Setup Environment and Mount Google Drive\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Add, PReLU, Concatenate, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import glob\n",
    "from google.colab import drive\n",
    "\n",
    "# Disable XLA JIT compilation to avoid ResizeBicubic issues\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# Check for GPU\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"WARNING: No GPU detected. Training will be very slow. Please enable a GPU runtime.\")\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# @title Step 2: Configure Paths and Parameters\n",
    "# --- IMPORTANT: UPDATE THIS PATH TO POINT TO THE FOLDER ---\n",
    "TFRECORD_FOLDER_PATH = '/content/drive/MyDrive/SuperResolutionProject images/'  # Folder containing TFRecord files\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "MODEL_SAVE_DIR = '/content/drive/MyDrive/SuperResolutionProduct_01/models/'\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "print(f\"Model will be saved to: {MODEL_SAVE_DIR}\")\n",
    "\n",
    "# Training Parameters\n",
    "SCALE_FACTOR = 4\n",
    "INPUT_HEIGHT = 64\n",
    "INPUT_WIDTH = 64\n",
    "CHANNELS = 3\n",
    "EPOCHS = 75\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "\n",
    "# @title Step 3: Define Data Loading Functions\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'vis-red': tf.io.FixedLenFeature([], tf.string),\n",
    "        'vis-green': tf.io.FixedLenFeature([], tf.string),\n",
    "        'vis-blue': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    r = tf.io.decode_raw(example['vis-red'], tf.uint8)\n",
    "    g = tf.io.decode_raw(example['vis-green'], tf.uint8)\n",
    "    b = tf.io.decode_raw(example['vis-blue'], tf.uint8)\n",
    "    image_shape = tf.cast([256, 256, 3], tf.int32)\n",
    "    image = tf.reshape(tf.stack([r, g, b], axis=-1), image_shape)\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_lr_pair(hr_image, scale=SCALE_FACTOR):\n",
    "    hr_image = tf.cast(hr_image, tf.float32) / 255.0\n",
    "    hr_shape = tf.shape(hr_image)\n",
    "    lr_height = hr_shape[0] // scale\n",
    "    lr_width = hr_shape[1] // scale\n",
    "\n",
    "    lr1 = tf.image.resize(hr_image, [lr_height, lr_width], method='bicubic')\n",
    "    hr_shifted = hr_image[1:, 1:, :]  # Sub-pixel shift simulation\n",
    "    lr2 = tf.image.resize(hr_shifted, [lr_height, lr_width], method='bicubic')\n",
    "\n",
    "    lr1 = lr1[:lr_height, :lr_width, :]\n",
    "    lr2 = lr2[:lr_height, :lr_width, :]\n",
    "\n",
    "    hr_cropped = hr_image[:lr_height * scale, :lr_width * scale, :]\n",
    "    return (lr1, lr2), hr_cropped\n",
    "\n",
    "\n",
    "def create_training_dataset(tfrecord_path, batch_size):\n",
    "    tfrecord_files = glob.glob(os.path.join(tfrecord_path, 'hr_image-*.tfrecord'))\n",
    "    print(f\"Found TFRecord files: {tfrecord_files}\")  # Debugging print\n",
    "\n",
    "    if not tfrecord_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"FATAL: No TFRecord files found at '{tfrecord_path}'. Please check the path.\"\n",
    "        )\n",
    "\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    hr_dataset = raw_dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = hr_dataset.map(create_lr_pair, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset.shuffle(100).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# @title Step 4: Define the Advanced Generator Model Architecture (FIXED)\n",
    "def res_block(x_in, num_filters):\n",
    "    x = Conv2D(num_filters, (3, 3), padding='same')(x_in)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    x = Conv2D(num_filters, (3, 3), padding='same')(x)\n",
    "    x = Add()([x_in, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ba109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, Concatenate, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_generator():\n",
    "    # Dual inputs\n",
    "    input1 = Input(shape=(INPUT_HEIGHT, INPUT_WIDTH, CHANNELS), name='lr1_input')\n",
    "    input2 = Input(shape=(INPUT_HEIGHT, INPUT_WIDTH, CHANNELS), name='lr2_input')\n",
    "    \n",
    "    # Concatenate inputs along channels\n",
    "    x = Concatenate()([input1, input2])  # Shape: (64, 64, 6)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    \n",
    "    # SOLUTION 1: Use UpSampling2D instead of Resizing layer\n",
    "    # This avoids the XLA compilation issue\n",
    "    x = UpSampling2D(size=(SCALE_FACTOR, SCALE_FACTOR), interpolation='bilinear')(x)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    outputs = Conv2D(CHANNELS, kernel_size=3, padding='same', activation='sigmoid')(x)  # Changed to sigmoid for [0,1] range\n",
    "    \n",
    "    generator = Model(inputs=[input1, input2], outputs=outputs)\n",
    "    return generator\n",
    "\n",
    "\n",
    "# Alternative generator using transpose convolution (uncomment to use)\n",
    "def build_generator_alternative():\n",
    "    \"\"\"Alternative generator using transpose convolutions for upsampling\"\"\"\n",
    "    input1 = Input(shape=(INPUT_HEIGHT, INPUT_WIDTH, CHANNELS), name='lr1_input')\n",
    "    input2 = Input(shape=(INPUT_HEIGHT, INPUT_WIDTH, CHANNELS), name='lr2_input')\n",
    "    \n",
    "    # Concatenate inputs along channels\n",
    "    x = Concatenate()([input1, input2])  # Shape: (64, 64, 6)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Use transpose convolution for upsampling\n",
    "    x = Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu')(x)  # 64x64 -> 128x128\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu')(x)   # 128x128 -> 256x256\n",
    "    \n",
    "    outputs = Conv2D(CHANNELS, kernel_size=3, padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    generator = Model(inputs=[input1, input2], outputs=outputs)\n",
    "    return generator\n",
    "\n",
    "\n",
    "# @title Step 5: Train the Model\n",
    "print(\"--- Starting Model Training ---\")\n",
    "\n",
    "print(\"1. Creating training dataset...\")\n",
    "try:\n",
    "    train_dataset = create_training_dataset(TFRECORD_FOLDER_PATH, BATCH_SIZE)\n",
    "    print(\"   Dataset created successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    raise SystemExit()\n",
    "\n",
    "print(\"2. Building generator model...\")\n",
    "generator = build_generator()  # Use build_generator_alternative() for the alternative approach\n",
    "generator.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mse')  # Changed to MSE for better convergence\n",
    "print(\"   Model built and compiled.\")\n",
    "generator.summary()\n",
    "\n",
    "model_filepath = os.path.join(MODEL_SAVE_DIR, 'sr_generator_best.h5')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_filepath,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "print(\"\\n3. Starting training process...\")\n",
    "history = generator.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Finished! ---\")\n",
    "print(f\"âœ… Best model saved to: {model_filepath}\")\n",
    "print(\"You can now download this file from your Google Drive and use it in the Streamlit application.\")\n",
    "\n",
    "# @title Step 6: Save Final Model and Training History\n",
    "import pickle\n",
    "\n",
    "# Save the final model\n",
    "final_model_path = os.path.join(MODEL_SAVE_DIR, 'sr_generator_final.h5')\n",
    "generator.save(final_model_path)\n",
    "\n",
    "# Save training history\n",
    "history_path = os.path.join(MODEL_SAVE_DIR, 'training_history.pkl')\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(f\"âœ… Final model saved to: {final_model_path}\")\n",
    "print(f\"âœ… Training history saved to: {history_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
